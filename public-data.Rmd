---
title: "Importing publicly available data"
author: "Mark Dunning"
date: "22 December 2015"
output: html_document
---


# Bioconductor data packages

The bioconductor project includes a collection of [Experimental Data](http://bioconductor.org/packages/release/BiocViews.html#___ExperimentData) packages that can be downloaded and installed in the same way as regular software packages in Bioconductor

## Example data for a package

The size limit for a new package submission is quite restrictive, so authors often have to submit example datasets separately. 
e.g. The [beadrrayExampleData](http://bioconductor.org/packages/release/data/experiment/html/beadarrayExampleData.html) has example data which can be used to test examples from the beadarray package


## Supplementary data for a paper

e.g. from the [Markowetz lab @ CI](http://bioconductor.org/packages/release/data/experiment/html/Fletcher2013a.html). This package not only has the data, but R scripts to reproduce the analysis in the paper.

## Curated datasets for meta-analysis

Several breast cancer datasets have been curated for use with the genefu package; which has many useful functions for classication of breast cancer

- [breastCancerNKI](http://bioconductor.org/packages/release/data/experiment/html/breastCancerNKI.html)
- [breastCancerVDX](http://bioconductor.org/packages/release/data/experiment/html/breastCancerVDX.html)

also

- curatedBreastData

******

# Data from Gene Expression Omnibus (GEO)

## Using the GEOquery package

Can search from GEO [home page](http://www.ncbi.nlm.nih.gov/geo/) or using this [Shiny app](https://zhiji.shinyapps.io/GEOsearch) to get a dataset ID which will be of the form **GSE....**.

With this identifier, we can use the GEOquery Bioconductor package

```{r message=FALSE}
library(GEOquery)
```

## Example 1. General procedure

Lets say we have identified a dataset which has breast cancer cell lines. The web page describing these data is [here](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE3156). The main function we need to use is `getGEO`. This downloads the *series* file for the dataset and parses the data in this file into a format that is compatible with Bioconductor. 

```{r eval=FALSE}
mydata <- getGEO("GSE3156")
mydata
```

sometimes datasets in GEO can include more than one platform (technology) so the result is returned in the form of a list; one item in the list for each platform. In this case, even though there is only one platform used, we have to subset the object.

```{r eval=FALSE}
mydata[[1]]
```


***The recommended approach*** is to download to disk first. On the [page](http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE3156) for the dataset you should see there is a link to the **Series Matrix File(s)**. You can copy and paste this link into R and use the `download.file` function to get data from the URL to disk. GEOquery is then able to read from this file in future using the filename argument. 

Advantage is that you don't need an internet connection to run your script

```{r cache=TRUE}
remotefile <- 'ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE3nnn/GSE3156/matrix/GSE3156_series_matrix.txt.gz'
download.file(remotefile, destfile="GSE3156_series_matrix.txt.gz")
mydata <- getGEO(filename="GSE3156_series_matrix.txt.gz")
mydata
```

The structure of the `mydata` object should be quite familiar to you. The expression values can be retrieved by the `exprs` function. Here, we just print the first 5 rows and 5 columns. In total there are `r nrow(mydata)` rows (genes) and `r ncol(mydata)` columns (samples)

******
## Q. What scale are the expression values recorded on? Is this an appropriate scale for analysis / visualisation?

******


```{r}
exprs(mydata)[1:5,1:5]
summary(exprs(mydata))
```

## Example 1.1 Quality assessment of the downloaded data

As we have downloaded the processed and normalised data, there are limited options in terms of quality assessment. Without the *.cel* files we cannot examine the raw images or fit PLMs. The simplest form of QA is the boxplot.


```{r}
boxplot(log2(exprs(mydata)))
```

The ***arrayQualityMetrics*** package can automatically-generate a variety of QA plots. It incorporates clustering methods that we will explore in-depth later in the course. Such methods are extremely useful for verifying known relationships between sample groups.


******
## Q. Generate an arrayQualityMetrics report for the dataset. Do any arrays seem to be poor quality?

The report should be generated in a folder called `arrayQualityMetrics report for mydata` (the name of the directory can be configured).
******

```{r message=FALSE,cache=TRUE,warning=FALSE}
library(arrayQualityMetrics)
arrayQualityMetrics(mydata, force=TRUE)
```


We can remove samples from our `ExpressionSet` object using the same subsetting rules that apply when removing columns from a matrix or data frame. Consider the following example; whereas `a[,1]` prints the first column, `a[,-1]` prints the matrix with all columns *except* the first one.

```{r}
a <- matrix(rnorm(100),ncol=10)
colnames(a) <- LETTERS[1:10]
a[,1]
a[,-1]
```

The same technique applies to vectors with more than one element

```{r}
a[,c(1,10)]
a[,-c(1,10)]
```

The `ExpressionSet` object has been design to respect these same subsetting rules, even though it is an inherently more-complicated object.

In the following we create a new object that represents the first four *samples* in the object. This is especially neat, as it creates a subset of the expression matrix and phenotypic data in the same operation. At the same time, the number of genes is not affected. 


```{r}
subset <- mydata[,1:4]
dim(exprs(subset))
dim(pData(subset))
```

Consequently, to *remove* the first four samples, we could do;

```{r}
subset <- mydata[,-c(1,4)]
subset
```

So in order to remove one or more poor-quality arrays we need to know their indices.

Finally, when creating a subset of an `ExpressionSet` object, we can also filter on rows. e.g. to select the first 100 genes.

```{r}
subset <- mydata[1:100,]
```

In the next section we will look into the annotation of the dataset in more detail

## Example 1.2 - Dealing with gene annotation

The annotation for the features can be retrieved by using `fData`. Because of the strict submission process, all the rows of this feature matrix are in the same order as the expression matrix; which greatly-simplifies further analysis

```{r}
fData(mydata)[1:5,1:5]
colnames(fData(mydata))
all(rownames(fData(mydata)) == rownames(exprs(mydata)))
```

Although this is an Affymetrix experiment, the `annotation` is set to `r annotation(mydata)`, which is the GEO identifier for this paticular platform. All experiments in GEO run on this platform get annotated with the same table (a *SOFT* file). During the process of importing the dataset, `GEOquery` will automatically download this *SOFT* file for you.

```{r}
features <- fData(mydata)
```


Recall that a particular column from the feature matrix can be retrieved using the `$` syntax. The results will be a vector with a length corresponding to the number of genes in the experiment (in this case `r nrow(fData(mydata))`). So take care if running this line of code! We probably won't want to print all IDs to the screen, but we may wish to save as a variable in further analysis.

```{r eval=FALSE}
colnames(features)
```


## Exercise

- How many unique Entrez gene IDs are there?
- How many features do not have an associated Entrez ID
- Which Entrez ID has the most probes?
- What probes are used for the gene *TP53*

```{r}
length(unique(features$ENTREZ_GENE_ID))
```


## Example 1.3 Filtering the expression data

From our answers, we should note that 

1) some genes do not have an Entrez ID
2) some genes have multiple probes

Quite often for an expression analysis we want

- to map to other annotation sources using Entrez ID
- measurements from reliable annotation sources
- one measurement per gene

Therefore, it makes sense to

- exclude probes with no Entrez gene identifier
- collapse multiple probes to one
    + alternatively, choose one probe per-gene
    
***check that you understand why these give the same result**

```{r}
noEntrez <- which(features$ENTREZ_GENE_ID == "")
mydata.filt <- mydata[-noEntrez,]
dim(mydata.filt)

hasEntrez <- which(features$ENTREZ_GENE_ID != "")
mydata.filt <- mydata[hasEntrez,]
dim(mydata.filt)
```

As it turns out, the `genefilter` package has some useful features for doing this.

```{r}
annotation(mydata) <- "hgu133a2"
```

## Example 2. Dealing with large cohorts

For this second example, we will import a patient cohort
```{r}
remotefile <- 'ftp://ftp.ncbi.nlm.nih.gov/geo/series/GSE18nnn/GSE18088/matrix/GSE18088_series_matrix.txt.gz'
download.file(remotefile, destfile="data/GSE18088_series_matrix.txt.gz")
cohort <- getGEO(filename="data/GSE18088_series_matrix.txt.gz")
cohort
```

As before, we can query the expression matrix and features

```{r}
head(exprs(cohort)[,1:5])
head(fData(cohort)[,1:5])
```

But an extra feature of this dataset is the availability of clinical information

```{r}
pData(cohort)[1:5,1:5]
colnames(pData(cohort))
```

```{r}
pd <- pData(cohort)
View(pd)
```

The interesting columns tend to be in columns starting "characteristics_"

```{r}
pd[1:4,10:16]
```

******

Q. How many males and females are there in the study?
Q. How many of the patients relapsed?

******

```{r echo=FALSE}
table(pd$characteristics_ch1.1)
table(pd$characteristics_ch1.2)
```

******
Q. What is the age distribution of the samples?

******

```{r echo=FALSE}
clinvars <- pd[,10:16]
clinvars$characteristics_ch1.4 <- as.numeric(gsub("age at diagnosis, years: ","",clinvars$characteristics_ch1.4))
hist(clinvars$characteristics_ch1.4)
```

This is trickier without extra manipulation of the data. R supports various string-cleaning operations such as substituting text, trimming etc. A commonly-used function is `gsub` (`?gsub`) which replaces a given *pattern* with a *replacement* string for every element in a character vector. In this case, we want to replace `age at diagnosis, years: ` with the blank string `""`. The R code is thus;

```{r}
clinvars <- pd[,10:16]
gsub("age at diagnosis, years: ","",clinvars$characteristics_ch1.4)
```

However, R still treats the result as a character vector (as each item has `""` around it). We need to explicitly convert to numeric values before proceeding

```{r}
clinvars$characteristics_ch1.4 <- as.numeric(gsub("age at diagnosis, years: ","",clinvars$characteristics_ch1.4))
hist(clinvars$characteristics_ch1.4)
```

******
Q. Clean-up the gender column so that the values are either `male` or `female`.

******

```{r echo=FALSE}
sex<- gsub("gender: ","",clinvars$characteristics_ch1.1)
table(sex)
```

Another relevant function is `substr`, which prints the portion of a string between a start and end position. In other case, we want strings that start after the `:` character (which is letter number 9) and go all the way to the end of the string. The length of the string can vary, but can be retrieved using the `nchar` function

```{r}
nchar(as.character(clinvars$characteristics_ch1.1))
sex <- substr(clinvars$characteristics_ch1.1,9,nchar(as.character(clinvars$characteristics_ch1.1)))
sex
```

The `separate` function from the `tidyr` package can also be of some use. It can be used on a column where all the entries contain some common separator, in our case `:`. 

```{r}
library(tidyr)
clinvars <- separate(clinvars, col="characteristics_ch1.1",sep=":",into=c("characteristics_ch1.1","gender"))
head(clinvars)
```


